{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Banking Fraud with various Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import AWS specific modules and specify S3 data location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install --upgrade pip\n",
    "# !{sys.executable} -m pip install --upgrade seaborn\n",
    "# !{sys.executable} -m pip install --upgrade imbalanced-learn\n",
    "import boto3\n",
    "import os\n",
    "from random import seed, sample\n",
    "import sagemaker\n",
    "import sagemaker.amazon.amazon_estimator\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.serializers import CSVSerializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import python ML modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score, roc_curve, auc, precision_score, recall_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'sagemaker-pmelvin'\n",
    "prefix = 'compile_xgb_v3'\n",
    "hp_prefix = 'hp_tuning_v3'\n",
    "\n",
    "csv_data = 'input-data/bb_banking_fraud.csv'\n",
    "csv_removed_types = 'input-data/removed-specific-types/01a89090-e9b6-4b07-8a49-b0244d6dc035.csv'\n",
    "full_data_location = 's3://{}/{}'.format(bucket, csv_data)\n",
    "clean_data_location = 's3://{}/{}'.format(bucket, csv_removed_types)\n",
    "\n",
    "#local_file = 'bb_banking_fraud.csv'\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "smclient = boto3.Session().client('sagemaker')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-pmelvin/input-data/bb_banking_fraud.csv to ./bb_banking_fraud.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp 's3://sagemaker-pmelvin/input-data/bb_banking_fraud.csv' 'bb_banking_fraud.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.13 s, sys: 963 ms, total: 9.09 s\n",
      "Wall time: 9.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# df_full = pd.read_csv(full_data_location)\n",
    "df_full = pd.read_csv('bb_banking_fraud.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# df_clean = pd.read_csv(clean_data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_u = df_full.rename(columns={'oldbalanceOrg':'oldBalanceOrig', 'newbalanceOrig':'newBalanceOrig', 'oldbalanceDest':'oldBalanceDest', 'newbalanceDest':'newBalanceDest', 'isfraud':'isFraud'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_u_copy = df_u.copy()\n",
    "\n",
    "df_u['hourOfDay'] = np.nan\n",
    "df_u.hourOfDay = df_u_copy.step % 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_col = df_u.pop('isFraud')\n",
    "df_u.insert(0, 'isFraud', first_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isFraud</th>\n",
       "      <th>step</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldBalanceOrig</th>\n",
       "      <th>newBalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldBalanceDest</th>\n",
       "      <th>newBalanceDest</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "      <th>hourOfDay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>9839.64</td>\n",
       "      <td>C1231006815</td>\n",
       "      <td>170136.0</td>\n",
       "      <td>160296.36</td>\n",
       "      <td>M1979787155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>1864.28</td>\n",
       "      <td>C1666544295</td>\n",
       "      <td>21249.0</td>\n",
       "      <td>19384.72</td>\n",
       "      <td>M2044282225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C1305486145</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C553264065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C840083671</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C38997010</td>\n",
       "      <td>21182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>11668.14</td>\n",
       "      <td>C2048537720</td>\n",
       "      <td>41554.0</td>\n",
       "      <td>29885.86</td>\n",
       "      <td>M1230701703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   isFraud  step      type    amount     nameOrig  oldBalanceOrig  \\\n",
       "0        0     1   PAYMENT   9839.64  C1231006815        170136.0   \n",
       "1        0     1   PAYMENT   1864.28  C1666544295         21249.0   \n",
       "2        1     1  TRANSFER    181.00  C1305486145           181.0   \n",
       "3        1     1  CASH_OUT    181.00   C840083671           181.0   \n",
       "4        0     1   PAYMENT  11668.14  C2048537720         41554.0   \n",
       "\n",
       "   newBalanceOrig     nameDest  oldBalanceDest  newBalanceDest  \\\n",
       "0       160296.36  M1979787155             0.0             0.0   \n",
       "1        19384.72  M2044282225             0.0             0.0   \n",
       "2            0.00   C553264065             0.0             0.0   \n",
       "3            0.00    C38997010         21182.0             0.0   \n",
       "4        29885.86  M1230701703             0.0             0.0   \n",
       "\n",
       "   isFlaggedFraud  hourOfDay  \n",
       "0               0          1  \n",
       "1               0          1  \n",
       "2               0          1  \n",
       "3               0          1  \n",
       "4               0          1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_u.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df_u.sample(n=10000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(df):\n",
    "    \n",
    "    selected_cols = [\n",
    "        'type', 'amount', 'oldBalanceOrig', 'newBalanceOrig',\n",
    "        'oldBalanceDest', 'newBalanceDest', 'isFraud', 'hourOfDay'\n",
    "    ]\n",
    "    \n",
    "    df = df[selected_cols].copy()\n",
    "    dummies = pd.get_dummies(df.type)\n",
    "    df = pd.concat([df, dummies], axis=1).drop(\"type\", axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_data(pca_df):\n",
    "    pca_df = pca_df.copy()\n",
    "    target = pca_df.pop(\"isFraud\")\n",
    "    scaler = StandardScaler()\n",
    "    pca_df = scaler.fit_transform(pca_df)\n",
    "    pca = PCA(n_components=2)\n",
    "    components = pca.fit_transform(pca_df)\n",
    "\n",
    "    comp_df = pd.DataFrame(components, columns=[\"X\", \"y\"])\n",
    "    target = target.reset_index(drop=True)\n",
    "    plot_df = pd.concat([comp_df, target], axis=1)\n",
    "    \n",
    "    return plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fraud_plot(plot_df, maj_alpha=0.5, min_alpha=1, save=None):\n",
    "#     fig, ax = plt.subplots(figsize=(8, 6))\n",
    "#     ax = sns.scatterplot(x=\"X\", y=\"y\", alpha=maj_alpha, data=plot_df[plot_df.isFraud == 0], label=\"Legitimate\")\n",
    "#     sns.scatterplot(x=\"X\", y=\"y\", alpha=min_alpha, data=plot_df[plot_df.isFraud == 1], ax=ax, label=\"Fraud\")\n",
    "#     plt.title(\"Legitimate vs Fraudulent Purchases\")\n",
    "#     plt.tight_layout()\n",
    "#     if save != None:\n",
    "#         plt.savefig(save)\n",
    "#     plt.show()\n",
    "    \n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_data = get_features(sample)\n",
    "# plot_df = reduce_data(processed_data)\n",
    "# fraud_plot(plot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_data.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "RUS = RandomUnderSampler(sampling_strategy={0: 9589}, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(df, method):\n",
    "    processed_df = get_features(df)\n",
    "    target = processed_df.pop('isFraud')\n",
    "\n",
    "    processed_x, processed_y = method.fit_resample(processed_df, target)\n",
    "\n",
    "    cols = list(processed_df.columns) + [\"isFraud\"]\n",
    "\n",
    "    pdf_x = pd.DataFrame(processed_x, columns=processed_df.columns)\n",
    "    pdf_y = pd.DataFrame(processed_y, columns=['isFraud'])\n",
    "    resampled_df = pd.concat([pdf_x, pdf_y], axis=1)\n",
    "    \n",
    "    return resampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.55 s, sys: 865 ms, total: 3.42 s\n",
      "Wall time: 3.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rus_resampled = resample(df_u, RUS)\n",
    "# print(rus_resampled.shape)\n",
    "# print(rus_resampled.isFraud.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraud_plot(reduce_data(rus_resampled), min_alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import SMOTE\n",
    "# SM = SMOTE(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# sm_resampled = resample(df_u, SM)\n",
    "# print(sm_resampled.shape)\n",
    "# print(sm_resampled.isFraud.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm_sample = sm_resampled.sample(n=10000, random_state=42)\n",
    "# fraud_plot(reduce_data(sm_sample), min_alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Splitting and standardising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_col = rus_resampled.pop('isFraud')\n",
    "rus_resampled.insert(0, 'isFraud', first_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17802, 12)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rus_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isFraud</th>\n",
       "      <th>amount</th>\n",
       "      <th>oldBalanceOrig</th>\n",
       "      <th>newBalanceOrig</th>\n",
       "      <th>oldBalanceDest</th>\n",
       "      <th>newBalanceDest</th>\n",
       "      <th>hourOfDay</th>\n",
       "      <th>CASH_IN</th>\n",
       "      <th>CASH_OUT</th>\n",
       "      <th>DEBIT</th>\n",
       "      <th>PAYMENT</th>\n",
       "      <th>TRANSFER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>183806.32</td>\n",
       "      <td>19391.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>382572.19</td>\n",
       "      <td>566378.51</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>521.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3478.18</td>\n",
       "      <td>19853.00</td>\n",
       "      <td>16374.82</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1716.05</td>\n",
       "      <td>5769.17</td>\n",
       "      <td>4053.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>253129.93</td>\n",
       "      <td>1328499.49</td>\n",
       "      <td>1581629.42</td>\n",
       "      <td>2713220.48</td>\n",
       "      <td>2460090.55</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   isFraud     amount  oldBalanceOrig  newBalanceOrig  oldBalanceDest  \\\n",
       "0        0  183806.32        19391.00            0.00       382572.19   \n",
       "1        0     521.37            0.00            0.00            0.00   \n",
       "2        0    3478.18        19853.00        16374.82            0.00   \n",
       "3        0    1716.05         5769.17         4053.13            0.00   \n",
       "4        0  253129.93      1328499.49      1581629.42      2713220.48   \n",
       "\n",
       "   newBalanceDest  hourOfDay  CASH_IN  CASH_OUT  DEBIT  PAYMENT  TRANSFER  \n",
       "0       566378.51         18        0         1      0        0         0  \n",
       "1            0.00         17        0         0      0        1         0  \n",
       "2            0.00         11        0         0      0        1         0  \n",
       "3            0.00         19        0         0      0        1         0  \n",
       "4      2460090.55         18        1         0      0        0         0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rus_resampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rus_resampled.drop('isFraud', 1)\n",
    "y = rus_resampled.isFraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split the dataset with a 80% for training, 15% for validation and 5% for testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split train: 14241, val: 2670, test: 891 \n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.80\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.05\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1 - train_ratio, random_state=42)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1 - train_ratio, random_state=42, shuffle=True, stratify=y)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), random_state=42) \n",
    "# X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), random_state=42, shuffle=True, stratify=y) \n",
    "\n",
    "print('split train: {}, val: {}, test: {} '.format(X_train.shape[0], X_val.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "# scaler = RobustScaler()\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train),columns = X_train.columns)\n",
    "X_test  = pd.DataFrame(scaler.fit_transform(X_test),columns = X_test.columns)\n",
    "X_val   = pd.DataFrame(scaler.fit_transform(X_val),columns = X_val.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "X_train_ins = X_train.copy()\n",
    "X_test_ins  = X_test.copy()\n",
    "X_val_ins   = X_val.copy()\n",
    "\n",
    "X_train_ins.insert(0, 'isFraud', y_train.values)\n",
    "X_test_ins.insert(0, 'isFraud', y_test.values)\n",
    "X_val_ins.insert(0, 'isFraud', y_val.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "X_train.to_csv('train.csv', index=False, header=False)\n",
    "X_val.to_csv('validation.csv', index=False, header=False)\n",
    "\n",
    "# Save test and baseline with headers\n",
    "X_test.to_csv('test.csv', index=False, header=True)\n",
    "X_train.to_csv('baseline.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# convert to numpy arrays for later use\n",
    "X_train = X_train.to_numpy()\n",
    "X_test  = X_test.to_numpy()\n",
    "X_val   = X_val.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded training data location: s3://sagemaker-us-east-1-880038709331/blackbelt/v1/data/training/train.csv\n",
      "Uploaded validation data location: s3://sagemaker-us-east-1-880038709331/blackbelt/v1/data/validation/validation.csv\n",
      "Uploaded validation data location: s3://sagemaker-us-east-1-880038709331/blackbelt/v1/data/baseline/baseline.csv\n",
      "Training artifacts will be uploaded to: s3://sagemaker-us-east-1-880038709331/blackbelt/v1/output\n"
     ]
    }
   ],
   "source": [
    "# Get the session and default bucket\n",
    "session = sagemaker.session.Session()\n",
    "bucket = session.default_bucket()\n",
    "\n",
    "bb_prefix = 'blackbelt/v1'\n",
    "pl_prefix = 'pipeline'\n",
    "\n",
    "s3_train_uri = sess.upload_data('train.csv', bucket, bb_prefix + '/data/training')\n",
    "print('Uploaded training data location: {}'.format(s3_train_uri))\n",
    "\n",
    "s3_val_uri = sess.upload_data('validation.csv', bucket, bb_prefix + '/data/validation')\n",
    "print('Uploaded validation data location: {}'.format(s3_val_uri))\n",
    "\n",
    "s3_baseline_uri = sess.upload_data('baseline.csv', bucket, bb_prefix + '/data/baseline')\n",
    "print('Uploaded validation data location: {}'.format(s3_baseline_uri))\n",
    "\n",
    "s3_output_location = 's3://{}/{}/output'.format(bucket, bb_prefix)\n",
    "print('Training artifacts will be uploaded to: {}'.format(s3_output_location))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the build\n",
    "\n",
    "Load variables from environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region: us-east-1\n",
      "artifact bucket: mlops-bb-proj-artifact-us-east-1-880038709331\n",
      "pipeline: bb-proj\n",
      "model name: bb-proj\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import os\n",
    "import time\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "artifact_bucket = os.environ['ARTIFACT_BUCKET']\n",
    "pipeline_name = os.environ['PIPELINE_NAME']\n",
    "model_name = os.environ['MODEL_NAME']\n",
    "\n",
    "print('region: {}'.format(region))\n",
    "print('artifact bucket: {}'.format(artifact_bucket))\n",
    "print('pipeline: {}'.format(pipeline_name))\n",
    "print('model name: {}'.format(model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload data source meta data to trigger a new build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '3EE7B6E70E5819BA',\n",
       "  'HostId': 'cHtBCF5PAoudWaxJL7lzATxCLchqrucOzpu1pWtNRh8QaHnqFUf2i5isqpchNSH+wcmWYVP+m2w=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'cHtBCF5PAoudWaxJL7lzATxCLchqrucOzpu1pWtNRh8QaHnqFUf2i5isqpchNSH+wcmWYVP+m2w=',\n",
       "   'x-amz-request-id': '3EE7B6E70E5819BA',\n",
       "   'date': 'Fri, 08 Jan 2021 11:29:15 GMT',\n",
       "   'x-amz-version-id': 'EAD5AnQvLxl0yAIL7p3PU_FCVAjX2R4b',\n",
       "   'etag': '\"0306c53f41112bfd35000161be6369b3\"',\n",
       "   'content-length': '0',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"0306c53f41112bfd35000161be6369b3\"',\n",
       " 'VersionId': 'EAD5AnQvLxl0yAIL7p3PU_FCVAjX2R4b'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from io import BytesIO\n",
    "import zipfile\n",
    "import json\n",
    "\n",
    "input_data = {\n",
    "    'TrainingUri': s3_train_uri,\n",
    "    'ValidationUri': s3_val_uri,\n",
    "    'BaselineUri': s3_baseline_uri\n",
    "}\n",
    "\n",
    "hyperparameters = {\n",
    "    'num_round': 20\n",
    "}\n",
    "\n",
    "data_source_key = '{}/data-source.zip'.format(pipeline_name)\n",
    "\n",
    "zip_buffer = BytesIO()\n",
    "with zipfile.ZipFile(zip_buffer, 'a') as zf:\n",
    "    zf.writestr('inputData.json', json.dumps(input_data))\n",
    "    zf.writestr('hyperparameters.json', json.dumps(hyperparameters))\n",
    "zip_buffer.seek(0)\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "s3.put_object(Bucket=artifact_bucket, Key=data_source_key, Body=bytearray(zip_buffer.read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the training and baseline job is complete we can inspect the exeriment metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import analytics\n",
    "model_analytics = analytics.ExperimentAnalytics(experiment_name=model_name)\n",
    "analytics_df = model_analytics.dataframe()\n",
    "\n",
    "if (analytics_df.shape[0] == 0):\n",
    "    raise(Exception('Please wait.  No training or baseline jobs'))\n",
    "\n",
    "pd.set_option('display.max_colwidth', 100) # Increase column width to show full copmontent name\n",
    "cols = ['TrialComponentName', 'DisplayName', 'SageMaker.InstanceType', \n",
    "        'train:rmse - Last', 'validation:rmse - Last'] # return the last rmse for training and validation\n",
    "analytics_df[analytics_df.columns & cols].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dev Deployment\n",
    "\n",
    "Once the endpoint has been deployed and awaiting approval, we can begin some tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train = sagemaker.inputs.TrainingInput(\"s3://{}/{}/{}/\".format(bucket, pl_prefix, 'data/training'), content_type='text/csv')\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(\"s3://{}/{}/{}/\".format(bucket, pl_prefix, 'data/validation'), content_type='text/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_container = sagemaker.image_uris.retrieve('xgboost', boto3.Session().region_name, '1.0-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_type='ml.m5.xlarge'\n",
    "\n",
    "hyperparameters = {\n",
    "        \"alpha\":\"0.2\",\n",
    "        \"max_depth\":\"10\",\n",
    "        \"eta\":\"0.12\",\n",
    "        \"gamma\":\"2.0\",\n",
    "        \"min_child_weight\":\"8.5\",\n",
    "        \"subsample\":\"0.6\",\n",
    "        \"objective\":\"binary:logistic\",\n",
    "        \"num_round\":\"20\",\n",
    "        \"eval_metric\":\"auc\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_xgb = sagemaker.estimator.Estimator(image_uri=xgboost_container,\n",
    "                                          hyperparameters=hyperparameters,\n",
    "                                          role=sagemaker.get_execution_role(), \n",
    "                                          instance_count=1, \n",
    "                                          instance_type=instance_type,\n",
    "                                          output_path=s3_output_location,\n",
    "                                          sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "smote_xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})\n",
    "\n",
    "# use if you only want to train and not validate\n",
    "# smote_xgb.fit({'train': s3_input_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "deploy_instance_type='ml.m5.large'\n",
    "smote_predictor = smote_xgb.deploy(initial_instance_count=1,\n",
    "                                   model_name=\"xgb-smote-model-02\",\n",
    "                                   endpoint_name=\"xgb-smote-endpoint-02\",\n",
    "                                   instance_type=deploy_instance_type,\n",
    "                                   serializer=CSVSerializer(),\n",
    "                                   deserializer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use if already deployed\n",
    "\n",
    "# endpoint_name = \"xgb-smote-endpoint-02\"\n",
    "# smote_predictor = sagemaker.predictor.Predictor(endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have trained the model we can use it to make predictions for the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(current_predictor, data, rows=500):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = ''\n",
    "    for array in split_array:\n",
    "        predictions = ','.join([predictions, current_predictor.predict(array).decode('utf-8')])\n",
    "\n",
    "    return np.fromstring(predictions[1:], sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "smote_raw_predictions = predict(smote_predictor, X_test[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_binary_predictions = np.where(smote_raw_predictions > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_train_preds = predict(smote_predictor, X_train[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_valid_preds = predict(smote_predictor, X_val[:, 1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_specificity(y_actual, y_pred, thresh):\n",
    "    # calculates specificity\n",
    "    return sum((y_pred < thresh) & (y_actual == 0)) /sum(y_actual ==0)\n",
    "\n",
    "def print_report(y_actual, y_pred, thresh):\n",
    "    \n",
    "    auc = roc_auc_score(y_actual, y_pred)\n",
    "    accuracy = accuracy_score(y_actual, (y_pred > thresh))\n",
    "    recall = recall_score(y_actual, (y_pred > thresh))\n",
    "    precision = precision_score(y_actual, (y_pred > thresh))\n",
    "    specificity = calc_specificity(y_actual, y_pred, thresh)\n",
    "\n",
    "    print('AUC:%.3f'%auc)\n",
    "    print('accuracy:%.3f'%accuracy)\n",
    "    print('recall:%.3f'%recall)\n",
    "    print('precision:%.3f'%precision)\n",
    "    print('specificity:%.3f'%specificity)\n",
    "    print(' ')\n",
    "    return auc, accuracy, recall, precision, specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's have a look at our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.1\n",
    "\n",
    "# print('XGBoost Classifier')\n",
    "print('Training:')\n",
    "xgb_train_auc, xgb_train_accuracy, xgb_train_recall, xgb_train_precision, xgb_train_specificity = print_report(y_train, y_train_preds, thresh)\n",
    "\n",
    "print('Validation:')\n",
    "xgb_valid_auc, xgb_valid_accuracy, xgb_valid_recall, xgb_valid_precision, xgb_valid_specificity = print_report(y_val, y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's have a look at the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_test, y_pred):\n",
    "\n",
    "    cm  = confusion_matrix(y_test, y_pred)\n",
    "    # Get the per-class normalized value for each cell\n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    # We color each cell according to its normalized value, annotate with exact counts.\n",
    "    ax = sns.heatmap(cm_norm, annot=cm, fmt=\"d\", cmap=\"Blues\")\n",
    "    ax.set(xticklabels=[\"non-fraud\", \"fraud\"], yticklabels=[\"non-fraud\", \"fraud\"])\n",
    "    ax.set_ylim([0,2])\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('Real Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_confusion_matrix(y_test, smote_binary_predictions)\n",
    "plot_confusion_matrix(y_test, smote_binary_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and now let's have a look at a ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "auc = round(roc_auc_score(y_train, y_train_preds), 4)\n",
    "print('AUC is ' + repr(auc))\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(y_train, y_train_preds)\n",
    "\n",
    "plt.title('ROC Curve')\n",
    "plt.plot(fpr, tpr, 'b',\n",
    "label='AUC = %0.2f'% auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.1])\n",
    "plt.ylim([-0.1,1.1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and finally we need to clean up all our resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_predictor.delete_model()\n",
    "smote_predictor.delete_endpoint()\n",
    "sm_client = boto3.client('sagemaker', region_name=boto3.Session().region_name)\n",
    "waiter = sm_client.get_waiter('endpoint_deleted')\n",
    "waiter.wait(EndpointName=\"xgb-smote-endpoint-02\")"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
