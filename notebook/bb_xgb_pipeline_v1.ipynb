{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Banking Fraud with various Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import AWS specific modules and specify S3 data location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install --upgrade pip\n",
    "# !{sys.executable} -m pip install --upgrade seaborn\n",
    "# !{sys.executable} -m pip install --upgrade imbalanced-learn\n",
    "import boto3\n",
    "import os\n",
    "from random import seed, sample\n",
    "import sagemaker\n",
    "import sagemaker.amazon.amazon_estimator\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.serializers import CSVSerializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import python ML modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score, roc_curve, auc, precision_score, recall_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'sagemaker-pmelvin'\n",
    "prefix = 'compile_xgb_v3'\n",
    "hp_prefix = 'hp_tuning_v3'\n",
    "\n",
    "csv_data = 'input-data/bb_banking_fraud.csv'\n",
    "csv_removed_types = 'input-data/removed-specific-types/01a89090-e9b6-4b07-8a49-b0244d6dc035.csv'\n",
    "full_data_location = 's3://{}/{}'.format(bucket, csv_data)\n",
    "clean_data_location = 's3://{}/{}'.format(bucket, csv_removed_types)\n",
    "\n",
    "#local_file = 'bb_banking_fraud.csv'\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "smclient = boto3.Session().client('sagemaker')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-pmelvin/input-data/bb_banking_fraud.csv to ./bb_banking_fraud.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp 's3://sagemaker-pmelvin/input-data/bb_banking_fraud.csv' 'bb_banking_fraud.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.13 s, sys: 963 ms, total: 9.09 s\n",
      "Wall time: 9.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# df_full = pd.read_csv(full_data_location)\n",
    "df_full = pd.read_csv('bb_banking_fraud.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# df_clean = pd.read_csv(clean_data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_u = df_full.rename(columns={'oldbalanceOrg':'oldBalanceOrig', 'newbalanceOrig':'newBalanceOrig', 'oldbalanceDest':'oldBalanceDest', 'newbalanceDest':'newBalanceDest', 'isfraud':'isFraud'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_u_copy = df_u.copy()\n",
    "\n",
    "df_u['hourOfDay'] = np.nan\n",
    "df_u.hourOfDay = df_u_copy.step % 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_col = df_u.pop('isFraud')\n",
    "df_u.insert(0, 'isFraud', first_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isFraud</th>\n",
       "      <th>step</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldBalanceOrig</th>\n",
       "      <th>newBalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldBalanceDest</th>\n",
       "      <th>newBalanceDest</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "      <th>hourOfDay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>9839.64</td>\n",
       "      <td>C1231006815</td>\n",
       "      <td>170136.0</td>\n",
       "      <td>160296.36</td>\n",
       "      <td>M1979787155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>1864.28</td>\n",
       "      <td>C1666544295</td>\n",
       "      <td>21249.0</td>\n",
       "      <td>19384.72</td>\n",
       "      <td>M2044282225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C1305486145</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C553264065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C840083671</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C38997010</td>\n",
       "      <td>21182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>11668.14</td>\n",
       "      <td>C2048537720</td>\n",
       "      <td>41554.0</td>\n",
       "      <td>29885.86</td>\n",
       "      <td>M1230701703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   isFraud  step      type    amount     nameOrig  oldBalanceOrig  \\\n",
       "0        0     1   PAYMENT   9839.64  C1231006815        170136.0   \n",
       "1        0     1   PAYMENT   1864.28  C1666544295         21249.0   \n",
       "2        1     1  TRANSFER    181.00  C1305486145           181.0   \n",
       "3        1     1  CASH_OUT    181.00   C840083671           181.0   \n",
       "4        0     1   PAYMENT  11668.14  C2048537720         41554.0   \n",
       "\n",
       "   newBalanceOrig     nameDest  oldBalanceDest  newBalanceDest  \\\n",
       "0       160296.36  M1979787155             0.0             0.0   \n",
       "1        19384.72  M2044282225             0.0             0.0   \n",
       "2            0.00   C553264065             0.0             0.0   \n",
       "3            0.00    C38997010         21182.0             0.0   \n",
       "4        29885.86  M1230701703             0.0             0.0   \n",
       "\n",
       "   isFlaggedFraud  hourOfDay  \n",
       "0               0          1  \n",
       "1               0          1  \n",
       "2               0          1  \n",
       "3               0          1  \n",
       "4               0          1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_u.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df_u.sample(n=10000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(df):\n",
    "    \n",
    "    selected_cols = [\n",
    "        'type', 'amount', 'oldBalanceOrig', 'newBalanceOrig',\n",
    "        'oldBalanceDest', 'newBalanceDest', 'isFraud', 'hourOfDay'\n",
    "    ]\n",
    "    \n",
    "    df = df[selected_cols].copy()\n",
    "    dummies = pd.get_dummies(df.type)\n",
    "    df = pd.concat([df, dummies], axis=1).drop(\"type\", axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_data(pca_df):\n",
    "    pca_df = pca_df.copy()\n",
    "    target = pca_df.pop(\"isFraud\")\n",
    "    scaler = StandardScaler()\n",
    "    pca_df = scaler.fit_transform(pca_df)\n",
    "    pca = PCA(n_components=2)\n",
    "    components = pca.fit_transform(pca_df)\n",
    "\n",
    "    comp_df = pd.DataFrame(components, columns=[\"X\", \"y\"])\n",
    "    target = target.reset_index(drop=True)\n",
    "    plot_df = pd.concat([comp_df, target], axis=1)\n",
    "    \n",
    "    return plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fraud_plot(plot_df, maj_alpha=0.5, min_alpha=1, save=None):\n",
    "#     fig, ax = plt.subplots(figsize=(8, 6))\n",
    "#     ax = sns.scatterplot(x=\"X\", y=\"y\", alpha=maj_alpha, data=plot_df[plot_df.isFraud == 0], label=\"Legitimate\")\n",
    "#     sns.scatterplot(x=\"X\", y=\"y\", alpha=min_alpha, data=plot_df[plot_df.isFraud == 1], ax=ax, label=\"Fraud\")\n",
    "#     plt.title(\"Legitimate vs Fraudulent Purchases\")\n",
    "#     plt.tight_layout()\n",
    "#     if save != None:\n",
    "#         plt.savefig(save)\n",
    "#     plt.show()\n",
    "    \n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_data = get_features(sample)\n",
    "# plot_df = reduce_data(processed_data)\n",
    "# fraud_plot(plot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_data.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "RUS = RandomUnderSampler(sampling_strategy={0: 9589}, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(df, method):\n",
    "    processed_df = get_features(df)\n",
    "    target = processed_df.pop('isFraud')\n",
    "\n",
    "    processed_x, processed_y = method.fit_resample(processed_df, target)\n",
    "\n",
    "    cols = list(processed_df.columns) + [\"isFraud\"]\n",
    "\n",
    "    pdf_x = pd.DataFrame(processed_x, columns=processed_df.columns)\n",
    "    pdf_y = pd.DataFrame(processed_y, columns=['isFraud'])\n",
    "    resampled_df = pd.concat([pdf_x, pdf_y], axis=1)\n",
    "    \n",
    "    return resampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.55 s, sys: 865 ms, total: 3.42 s\n",
      "Wall time: 3.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rus_resampled = resample(df_u, RUS)\n",
    "# print(rus_resampled.shape)\n",
    "# print(rus_resampled.isFraud.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraud_plot(reduce_data(rus_resampled), min_alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import SMOTE\n",
    "# SM = SMOTE(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# sm_resampled = resample(df_u, SM)\n",
    "# print(sm_resampled.shape)\n",
    "# print(sm_resampled.isFraud.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm_sample = sm_resampled.sample(n=10000, random_state=42)\n",
    "# fraud_plot(reduce_data(sm_sample), min_alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Splitting and standardising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_col = rus_resampled.pop('isFraud')\n",
    "rus_resampled.insert(0, 'isFraud', first_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17802, 12)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rus_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isFraud</th>\n",
       "      <th>amount</th>\n",
       "      <th>oldBalanceOrig</th>\n",
       "      <th>newBalanceOrig</th>\n",
       "      <th>oldBalanceDest</th>\n",
       "      <th>newBalanceDest</th>\n",
       "      <th>hourOfDay</th>\n",
       "      <th>CASH_IN</th>\n",
       "      <th>CASH_OUT</th>\n",
       "      <th>DEBIT</th>\n",
       "      <th>PAYMENT</th>\n",
       "      <th>TRANSFER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>183806.32</td>\n",
       "      <td>19391.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>382572.19</td>\n",
       "      <td>566378.51</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>521.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3478.18</td>\n",
       "      <td>19853.00</td>\n",
       "      <td>16374.82</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1716.05</td>\n",
       "      <td>5769.17</td>\n",
       "      <td>4053.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>253129.93</td>\n",
       "      <td>1328499.49</td>\n",
       "      <td>1581629.42</td>\n",
       "      <td>2713220.48</td>\n",
       "      <td>2460090.55</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   isFraud     amount  oldBalanceOrig  newBalanceOrig  oldBalanceDest  \\\n",
       "0        0  183806.32        19391.00            0.00       382572.19   \n",
       "1        0     521.37            0.00            0.00            0.00   \n",
       "2        0    3478.18        19853.00        16374.82            0.00   \n",
       "3        0    1716.05         5769.17         4053.13            0.00   \n",
       "4        0  253129.93      1328499.49      1581629.42      2713220.48   \n",
       "\n",
       "   newBalanceDest  hourOfDay  CASH_IN  CASH_OUT  DEBIT  PAYMENT  TRANSFER  \n",
       "0       566378.51         18        0         1      0        0         0  \n",
       "1            0.00         17        0         0      0        1         0  \n",
       "2            0.00         11        0         0      0        1         0  \n",
       "3            0.00         19        0         0      0        1         0  \n",
       "4      2460090.55         18        1         0      0        0         0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rus_resampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rus_resampled.drop('isFraud', 1)\n",
    "y = rus_resampled.isFraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split the dataset with a 80% for training, 15% for validation and 5% for testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split train: 14241, val: 2670, test: 891 \n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.80\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.05\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1 - train_ratio, random_state=42)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1 - train_ratio, random_state=42, shuffle=True, stratify=y)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), random_state=42) \n",
    "# X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), random_state=42, shuffle=True, stratify=y) \n",
    "\n",
    "print('split train: {}, val: {}, test: {} '.format(X_train.shape[0], X_val.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split train: 14241, val: 2670, test: 891 \n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.80\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.05\n",
    "\n",
    "X_train_pd, X_test_pd, y_train_pd, y_test_pd = train_test_split(X, y, test_size = 1 - train_ratio, random_state=42)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1 - train_ratio, random_state=42, shuffle=True, stratify=y)\n",
    "\n",
    "X_val_pd, X_test_pd, y_val_pd, y_test_pd = train_test_split(X_test_pd, y_test_pd, test_size=test_ratio/(test_ratio + validation_ratio), random_state=42) \n",
    "# X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), random_state=42, shuffle=True, stratify=y) \n",
    "\n",
    "print('split train: {}, val: {}, test: {} '.format(X_train_pd.shape[0], X_val_pd.shape[0], X_test_pd.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "# scaler = RobustScaler()\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_pd = MinMaxScaler()\n",
    "# scaler = RobustScaler()\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "scaler_pd.fit(X_train_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train),columns = X_train.columns)\n",
    "X_test  = pd.DataFrame(scaler.fit_transform(X_test),columns = X_test.columns)\n",
    "X_val   = pd.DataFrame(scaler.fit_transform(X_val),columns = X_val.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "X_train_pd = pd.DataFrame(scaler.fit_transform(X_train_pd),columns = X_train_pd.columns)\n",
    "X_tes_pdt  = pd.DataFrame(scaler.fit_transform(X_test_pd),columns = X_test_pd.columns)\n",
    "X_val_pd   = pd.DataFrame(scaler.fit_transform(X_val_pd),columns = X_val_pd.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "X_train_ins = X_train.copy()\n",
    "X_test_ins  = X_test.copy()\n",
    "X_val_ins   = X_val.copy()\n",
    "\n",
    "X_train_ins.insert(0, 'isFraud', y_train.values)\n",
    "X_test_ins.insert(0, 'isFraud', y_test.values)\n",
    "X_val_ins.insert(0, 'isFraud', y_val.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "X_train.to_csv('train.csv', index=False, header=False)\n",
    "X_val.to_csv('validation.csv', index=False, header=False)\n",
    "\n",
    "# Save test and baseline with headers\n",
    "X_test.to_csv('test.csv', index=False, header=True)\n",
    "X_train.to_csv('baseline.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# convert to numpy arrays for later use\n",
    "X_train = X_train.to_numpy()\n",
    "X_test  = X_test.to_numpy()\n",
    "X_val   = X_val.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded training data location: s3://sagemaker-us-east-1-880038709331/blackbelt/v1/data/training/train.csv\n",
      "Uploaded validation data location: s3://sagemaker-us-east-1-880038709331/blackbelt/v1/data/validation/validation.csv\n",
      "Uploaded validation data location: s3://sagemaker-us-east-1-880038709331/blackbelt/v1/data/baseline/baseline.csv\n",
      "Training artifacts will be uploaded to: s3://sagemaker-us-east-1-880038709331/blackbelt/v1/output\n"
     ]
    }
   ],
   "source": [
    "# Get the session and default bucket\n",
    "session = sagemaker.session.Session()\n",
    "bucket = session.default_bucket()\n",
    "\n",
    "bb_prefix = 'blackbelt/v1'\n",
    "pl_prefix = 'pipeline'\n",
    "\n",
    "s3_train_uri = sess.upload_data('train.csv', bucket, bb_prefix + '/data/training')\n",
    "print('Uploaded training data location: {}'.format(s3_train_uri))\n",
    "\n",
    "s3_val_uri = sess.upload_data('validation.csv', bucket, bb_prefix + '/data/validation')\n",
    "print('Uploaded validation data location: {}'.format(s3_val_uri))\n",
    "\n",
    "s3_baseline_uri = sess.upload_data('baseline.csv', bucket, bb_prefix + '/data/baseline')\n",
    "print('Uploaded validation data location: {}'.format(s3_baseline_uri))\n",
    "\n",
    "s3_output_location = 's3://{}/{}/output'.format(bucket, bb_prefix)\n",
    "print('Training artifacts will be uploaded to: {}'.format(s3_output_location))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the build\n",
    "\n",
    "Load variables from environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region: us-east-1\n",
      "artifact bucket: mlops-bb-proj-artifact-us-east-1-880038709331\n",
      "pipeline: bb-proj\n",
      "model name: bb-proj\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import os\n",
    "import time\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "artifact_bucket = os.environ['ARTIFACT_BUCKET']\n",
    "pipeline_name = os.environ['PIPELINE_NAME']\n",
    "model_name = os.environ['MODEL_NAME']\n",
    "\n",
    "print('region: {}'.format(region))\n",
    "print('artifact bucket: {}'.format(artifact_bucket))\n",
    "print('pipeline: {}'.format(pipeline_name))\n",
    "print('model name: {}'.format(model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload data source meta data to trigger a new build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '3EE7B6E70E5819BA',\n",
       "  'HostId': 'cHtBCF5PAoudWaxJL7lzATxCLchqrucOzpu1pWtNRh8QaHnqFUf2i5isqpchNSH+wcmWYVP+m2w=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'cHtBCF5PAoudWaxJL7lzATxCLchqrucOzpu1pWtNRh8QaHnqFUf2i5isqpchNSH+wcmWYVP+m2w=',\n",
       "   'x-amz-request-id': '3EE7B6E70E5819BA',\n",
       "   'date': 'Fri, 08 Jan 2021 11:29:15 GMT',\n",
       "   'x-amz-version-id': 'EAD5AnQvLxl0yAIL7p3PU_FCVAjX2R4b',\n",
       "   'etag': '\"0306c53f41112bfd35000161be6369b3\"',\n",
       "   'content-length': '0',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"0306c53f41112bfd35000161be6369b3\"',\n",
       " 'VersionId': 'EAD5AnQvLxl0yAIL7p3PU_FCVAjX2R4b'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from io import BytesIO\n",
    "import zipfile\n",
    "import json\n",
    "\n",
    "input_data = {\n",
    "    'TrainingUri': s3_train_uri,\n",
    "    'ValidationUri': s3_val_uri,\n",
    "    'BaselineUri': s3_baseline_uri\n",
    "}\n",
    "\n",
    "hyperparameters = {\n",
    "    'num_round': 20\n",
    "}\n",
    "\n",
    "data_source_key = '{}/data-source.zip'.format(pipeline_name)\n",
    "\n",
    "zip_buffer = BytesIO()\n",
    "with zipfile.ZipFile(zip_buffer, 'a') as zf:\n",
    "    zf.writestr('inputData.json', json.dumps(input_data))\n",
    "    zf.writestr('hyperparameters.json', json.dumps(hyperparameters))\n",
    "zip_buffer.seek(0)\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "s3.put_object(Bucket=artifact_bucket, Key=data_source_key, Body=bytearray(zip_buffer.read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the training and baseline job is complete we can inspect the exeriment metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrialComponentName</th>\n",
       "      <th>DisplayName</th>\n",
       "      <th>SageMaker.InstanceType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlops-bb-proj-pbl-c11b9980-6b81-483b-9c17-e549b25f1f8b-aws-processing-job</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>ml.m5.xlarge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mlops-bb-proj-c11b9980-6b81-483b-9c17-e549b25f1f8b-aws-training-job</td>\n",
       "      <td>Training</td>\n",
       "      <td>ml.m4.xlarge</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          TrialComponentName  \\\n",
       "0  mlops-bb-proj-pbl-c11b9980-6b81-483b-9c17-e549b25f1f8b-aws-processing-job   \n",
       "1        mlops-bb-proj-c11b9980-6b81-483b-9c17-e549b25f1f8b-aws-training-job   \n",
       "\n",
       "  DisplayName SageMaker.InstanceType  \n",
       "0    Baseline           ml.m5.xlarge  \n",
       "1    Training           ml.m4.xlarge  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker import analytics\n",
    "model_analytics = analytics.ExperimentAnalytics(experiment_name=model_name)\n",
    "analytics_df = model_analytics.dataframe()\n",
    "\n",
    "if (analytics_df.shape[0] == 0):\n",
    "    raise(Exception('Please wait.  No training or baseline jobs'))\n",
    "\n",
    "pd.set_option('display.max_colwidth', 100) # Increase column width to show full copmontent name\n",
    "cols = ['TrialComponentName', 'DisplayName', 'SageMaker.InstanceType', \n",
    "        'train:rmse - Last', 'validation:rmse - Last'] # return the last rmse for training and validation\n",
    "analytics_df[analytics_df.columns & cols].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dev Deployment\n",
    "\n",
    "Once the endpoint has been deployed and awaiting approval, we can begin some tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "endpoint name: mlops-bb-proj-dev-44465b83-4ea9-4098-971e-7ddd74bef6f0\n"
     ]
    }
   ],
   "source": [
    "codepipeline = boto3.client('codepipeline')\n",
    "\n",
    "def get_pipeline_stage(pipeline_name, stage_name):\n",
    "    response = codepipeline.get_pipeline_state(name=pipeline_name)\n",
    "    for stage in response['stageStates']:\n",
    "        if stage['stageName'] == stage_name:\n",
    "            return stage\n",
    "        \n",
    "# Get last execution id\n",
    "deploy_dev = get_pipeline_stage(pipeline_name, 'DeployDev')\n",
    "if not 'latestExecution' in deploy_dev:\n",
    "    raise(Exception('Please wait.  Deploy dev not started'))\n",
    "    \n",
    "execution_id = deploy_dev['latestExecution']['pipelineExecutionId']\n",
    "dev_endpoint_name = 'mlops-{}-dev-{}'.format(model_name, execution_id)\n",
    "\n",
    "print('endpoint name: {}'.format(dev_endpoint_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "try:\n",
    "    # Support SageMaker v2 SDK: https://sagemaker.readthedocs.io/en/stable/v2.html\n",
    "    from sagemaker.predictor import Predictor\n",
    "    from sagemaker.serializers import CSVSerializer\n",
    "    def get_predictor(endpoint_name):\n",
    "        xgb_predictor = Predictor(endpoint_name)\n",
    "        xgb_predictor.serializer = CSVSerializer()\n",
    "        return xgb_predictor\n",
    "except:\n",
    "    # Fallback to SageMaker v1.70 SDK\n",
    "    from sagemaker.predictor import RealTimePredictor, csv_serializer\n",
    "    def get_predictor(endpoint_name):\n",
    "        xgb_predictor = RealTimePredictor(endpoint_name)\n",
    "        xgb_predictor.content_type = 'text/csv'\n",
    "        xgb_predictor.serializer = csv_serializer\n",
    "        return xgb_predictor\n",
    "\n",
    "def predict(predictor, data, rows=500):\n",
    "    split_array = np.array_split(data, round(data.shape[0] / float(rows)))\n",
    "    predictions = ''\n",
    "    for array in tqdm(split_array):\n",
    "        predictions = ','.join([predictions, predictor.predict(array).decode('utf-8')])\n",
    "    return np.fromstring(predictions[1:], sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 13.90it/s]\n"
     ]
    }
   ],
   "source": [
    "dev_predictor = get_predictor(dev_endpoint_name)\n",
    "predictions = predict(dev_predictor, X_test[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_predictions = np.where(predictions > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 33.56it/s]\n"
     ]
    }
   ],
   "source": [
    "y_train_preds = predict(dev_predictor, X_train[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 31.22it/s]\n"
     ]
    }
   ],
   "source": [
    "y_valid_preds = predict(dev_predictor, X_val[:, 1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approve Prod Deployment\n",
    "\n",
    "If we are happy with this metric, we can go ahead and approve with the widget below, or manually in the CodePipeline  by clicking the \"Review\" button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"img/deploy-dev.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "def on_click(obj):\n",
    "    result = { 'summary': approval_text.value, 'status': obj.description }\n",
    "    response = codepipeline.put_approval_result(\n",
    "      pipelineName=pipeline_name,\n",
    "      stageName='DeployDev',\n",
    "      actionName='ApproveDeploy',\n",
    "      result=result,\n",
    "      token=approval_action['token']\n",
    "    )\n",
    "    button_box.close()\n",
    "    print(result)\n",
    "    \n",
    "# Create the widget if we are ready for approval\n",
    "deploy_dev = get_pipeline_stage(pipeline_name, 'DeployDev')\n",
    "if not 'latestExecution' in deploy_dev['actionStates'][-1]:\n",
    "    raise(Exception('Please wait.  Deploy dev not complete'))\n",
    "\n",
    "approval_action = deploy_dev['actionStates'][-1]['latestExecution']\n",
    "if approval_action['status'] == 'Succeeded':\n",
    "    print('Dev approved: {}'.format(approval_action['summary']))\n",
    "elif 'token' in approval_action:\n",
    "    approval_text = widgets.Text(placeholder='Optional approval message')   \n",
    "    approve_btn = widgets.Button(description=\"Approved\", button_style='success', icon='check')\n",
    "    reject_btn = widgets.Button(description=\"Rejected\", button_style='danger', icon='close')\n",
    "    approve_btn.on_click(on_click)\n",
    "    reject_btn.on_click(on_click)\n",
    "    button_box = widgets.HBox([approval_text, approve_btn, reject_btn])\n",
    "    display(button_box)\n",
    "else:\n",
    "    raise(Exception('Please wait.  No dev approval'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Production deployment is managed through a CloudFormation stack which performs the following:\n",
    "\n",
    "1. Creates SageMaker Endpoint with Data Capture and AutoScaling enabled\n",
    "2. Creates Model Monitoring Schedule with CloudWatch Alarm\n",
    "3. Deploys an API Gateway Lambda with AWS Code Deploy\n",
    "\n",
    "Image(\"img/cloud-formation.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the last events and how long ago they occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stack name: bb-proj-deploy-prd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogicalResourceId</th>\n",
       "      <th>ResourceStatus</th>\n",
       "      <th>ResourceStatusReason</th>\n",
       "      <th>TimeAgo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bb-proj-deploy-prd</td>\n",
       "      <td>CREATE_COMPLETE</td>\n",
       "      <td></td>\n",
       "      <td>00:16:27.238796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SagemakerScheduleAlarm</td>\n",
       "      <td>CREATE_COMPLETE</td>\n",
       "      <td></td>\n",
       "      <td>00:16:29.582796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SagemakerScheduleAlarm</td>\n",
       "      <td>CREATE_IN_PROGRESS</td>\n",
       "      <td>Resource creation Initiated</td>\n",
       "      <td>00:16:29.976796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SagemakerScheduleAlarm</td>\n",
       "      <td>CREATE_IN_PROGRESS</td>\n",
       "      <td></td>\n",
       "      <td>00:16:30.629796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ApiFunctionInvokePermissionProd</td>\n",
       "      <td>CREATE_COMPLETE</td>\n",
       "      <td></td>\n",
       "      <td>00:16:32.603796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 LogicalResourceId      ResourceStatus  \\\n",
       "0               bb-proj-deploy-prd     CREATE_COMPLETE   \n",
       "1           SagemakerScheduleAlarm     CREATE_COMPLETE   \n",
       "2           SagemakerScheduleAlarm  CREATE_IN_PROGRESS   \n",
       "3           SagemakerScheduleAlarm  CREATE_IN_PROGRESS   \n",
       "4  ApiFunctionInvokePermissionProd     CREATE_COMPLETE   \n",
       "\n",
       "          ResourceStatusReason         TimeAgo  \n",
       "0                              00:16:27.238796  \n",
       "1                              00:16:29.582796  \n",
       "2  Resource creation Initiated 00:16:29.976796  \n",
       "3                              00:16:30.629796  \n",
       "4                              00:16:32.603796  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from dateutil.tz import tzlocal\n",
    "\n",
    "def get_event_dataframe(events):\n",
    "    stack_cols = ['LogicalResourceId', 'ResourceStatus', 'ResourceStatusReason', 'Timestamp']\n",
    "    stack_event_df = pd.DataFrame(events)[stack_cols].fillna('')\n",
    "    stack_event_df['TimeAgo'] = (datetime.now(tzlocal())-stack_event_df['Timestamp'])\n",
    "    return stack_event_df.drop('Timestamp', axis=1)\n",
    "\n",
    "cfn = boto3.client('cloudformation')\n",
    "\n",
    "stack_name = stack_name='{}-deploy-prd'.format(pipeline_name)\n",
    "print('stack name: {}'.format(stack_name))\n",
    "\n",
    "# Get latest stack events\n",
    "while True:\n",
    "    try:\n",
    "        response = cfn.describe_stack_events(StackName=stack_name)\n",
    "        break\n",
    "    except ClientError as e:\n",
    "        print(e.response[\"Error\"][\"Message\"])\n",
    "    time.sleep(10)\n",
    "    \n",
    "get_event_dataframe(response['StackEvents']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prod endpoint: mlops-bb-proj-prd-44465b83-4ea9-4098-971e-7ddd74bef6f0\n"
     ]
    }
   ],
   "source": [
    "prd_endpoint_name='mlops-{}-prd-{}'.format(model_name, execution_id)\n",
    "print('prod endpoint: {}'.format(prd_endpoint_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  6.30it/s]\n"
     ]
    }
   ],
   "source": [
    "prd_predictor = get_predictor(prd_endpoint_name)\n",
    "\n",
    "predictions = predict(prd_predictor, X_test[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test Rest API\n",
    "\n",
    "Get back the deployment progress and rest API endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stack_status(stack_name):\n",
    "    response = cfn.describe_stacks(StackName=stack_name)\n",
    "    if response['Stacks']:\n",
    "        stack = response['Stacks'][0]\n",
    "        outputs = None\n",
    "        if 'Outputs' in stack:\n",
    "            outputs = dict([(o['OutputKey'], o['OutputValue']) for o in stack['Outputs']])\n",
    "        return stack['StackStatus'], outputs \n",
    "\n",
    "outputs = None\n",
    "while True:\n",
    "    try:\n",
    "        status, outputs = get_stack_status(stack_name)\n",
    "        response = smclient.describe_endpoint(EndpointName=prd_endpoint_name)\n",
    "        print(\"Endpoint status: {}\".format(response['EndpointStatus']))\n",
    "        if outputs:\n",
    "            break\n",
    "        elif status.endswith('FAILED'):\n",
    "            raise(Exception('Stack status: {}'.format(status)))\n",
    "    except ClientError as e:\n",
    "        print(e.response[\"Error\"][\"Message\"])\n",
    "    time.sleep(10)\n",
    "\n",
    "if outputs:\n",
    "    print('deployment application: {}'.format(outputs['DeploymentApplication']))\n",
    "    print('rest api: {}'.format(outputs['RestApi']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the deployment application to see if its created and started to shift traffic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a target=\"_blank\" href=\"https://us-east-1.console.aws.amazon.com/codesuite/codedeploy/applications/bb-proj-deploy-prd-ServerlessDeploymentApplication-1P6C9DDMHPDX1?region=us-east-1\">Deployment Application</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('<a target=\"_blank\" href=\"https://{0}.console.aws.amazon.com/codesuite/codedeploy/applications/{1}?region={0}\">Deployment Application</a>'.format(region, outputs['DeploymentApplication']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's ping the REST endpoint to see which SageMaker endpoint it is hitting.  Press STOP when deployment complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response code: 200: endpoint: mlops-bb-proj-prd-44465b83-4ea9-4098-971e-7ddd74bef6f0\n",
      "Deployment complete\n",
      "\n",
      "CPU times: user 26.5 ms, sys: 1.28 ms, total: 27.8 ms\n",
      "Wall time: 1.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from urllib import request\n",
    "\n",
    "headers = {\"Content-type\": \"text/csv\"}\n",
    "payload = X_test_pd[X_test_pd.columns[1:]].head(1).to_csv(header=False, index=False).encode('utf-8')\n",
    "rest_api = outputs['RestApi']\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        resp = request.urlopen(request.Request(rest_api, data=payload, headers=headers))\n",
    "        print(\"Response code: %d: endpoint: %s\" % (resp.getcode(), resp.getheader('x-sagemaker-endpoint')))\n",
    "        status, outputs = get_stack_status(stack_name) \n",
    "        if status.endswith('COMPLETE'):\n",
    "            print('Deployment complete\\n')\n",
    "            break\n",
    "        elif status.endswith('FAILED'):\n",
    "            raise(Exception('Stack status: {}'.format(status)))\n",
    "    except ClientError as e:\n",
    "        print(e.response[\"Error\"][\"Message\"])\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Monitor\n",
    "\n",
    "Get the latest production deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_prd = get_pipeline_stage(pipeline_name, 'DeployPrd')\n",
    "if not 'latestExecution' in deploy_prd:\n",
    "    raise(Exception('Please wait.  Deploy prd not complete'))\n",
    "    \n",
    "execution_id = deploy_prd['latestExecution']['pipelineExecutionId']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CloudWatch Monitoring\n",
    "\n",
    "AWS [CloudWatch Synthetics](https://aws.amazon.com/blogs/aws/new-use-cloudwatch-synthetics-to-monitor-sites-api-endpoints-web-workflows-and-more/) provides allow you to setup a canary to test that your API is returning an expected value on a regular interval.  This is a great way to validate that the blue/green deployment is not causing any downtime for our end-users.\n",
    "\n",
    "### Create Canary\n",
    "\n",
    "Let's setup a \"canary\" to continously test the production API, and a dashboard to visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating canary: mlops-bb-proj\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "from string import Template\n",
    "from io import BytesIO\n",
    "import zipfile\n",
    "\n",
    "# Format the canary_js with rest_api and payload\n",
    "rest_url = urlparse(rest_api)\n",
    "\n",
    "with open('canary.js') as f:\n",
    "    canary_js = Template(f.read()).substitute(hostname=rest_url.netloc, path=rest_url.path, \n",
    "                                              data=payload.decode('utf-8').strip())\n",
    "# Write the zip file\n",
    "zip_buffer = BytesIO()\n",
    "with zipfile.ZipFile(zip_buffer, 'w') as zf:\n",
    "    zip_path = 'nodejs/node_modules/apiCanaryBlueprint.js' # Set a valid path\n",
    "    zip_info = zipfile.ZipInfo(zip_path)\n",
    "    zip_info.external_attr = 0o0755 << 16 # Ensure the file is readable\n",
    "    zf.writestr(zip_info, canary_js)\n",
    "zip_buffer.seek(0)\n",
    "\n",
    "# Create the canary\n",
    "synth = boto3.client('synthetics')\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "s3_canary_uri = 's3://{}/{}'.format(artifact_bucket, model_name)\n",
    "canary_name = 'mlops-{}'.format(model_name)\n",
    "\n",
    "response = synth.create_canary(\n",
    "    Name=canary_name,\n",
    "    Code={\n",
    "        'ZipFile': bytearray(zip_buffer.read()),\n",
    "        'Handler': 'apiCanaryBlueprint.handler'\n",
    "    },\n",
    "    ArtifactS3Location=s3_canary_uri,\n",
    "    ExecutionRoleArn=role,\n",
    "    Schedule={ \n",
    "        'Expression': 'rate(10 minutes)', \n",
    "        'DurationInSeconds': 0 },\n",
    "    RunConfig={\n",
    "        'TimeoutInSeconds': 60,\n",
    "        'MemoryInMB': 960\n",
    "    },\n",
    "    SuccessRetentionPeriodInDays=31,\n",
    "    FailureRetentionPeriodInDays=31,\n",
    "    RuntimeVersion='syn-1.0',\n",
    ")\n",
    "\n",
    "print('Creating canary: {}'.format(canary_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the a CloudWatch alarm when success percent drops below 90% for that canary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating alarm: mlops-bb-proj-synth-lt-threshold\n"
     ]
    }
   ],
   "source": [
    "cloudwatch = boto3.client('cloudwatch')\n",
    "\n",
    "canary_alarm_name = '{}-synth-lt-threshold'.format(canary_name)\n",
    "\n",
    "response = cloudwatch.put_metric_alarm(\n",
    "    AlarmName=canary_alarm_name,\n",
    "    ComparisonOperator='LessThanThreshold',\n",
    "    EvaluationPeriods=1,\n",
    "    DatapointsToAlarm=1,\n",
    "    Period=600, # 10 minute interval\n",
    "    Statistic='Average',\n",
    "    Threshold=90.0,\n",
    "    ActionsEnabled=False,\n",
    "    AlarmDescription='SuccessPercent LessThanThreshold 90%',\n",
    "    Namespace='CloudWatchSynthetics',\n",
    "    MetricName='SuccessPercent',\n",
    "    Dimensions=[\n",
    "        {\n",
    "          'Name': 'CanaryName',\n",
    "          'Value': canary_name\n",
    "        },\n",
    "    ],\n",
    "    Unit='Seconds'\n",
    ")\n",
    "\n",
    "print('Creating alarm: {}'.format(canary_alarm_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's wait for the canary to be read, then start it and wait until running.  The"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canary status: RUNNING\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a target=\"_blank\" href=\"https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#synthetics:canary/detail/mlops-bb-proj\">CloudWatch Canary</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "while True:\n",
    "    try:\n",
    "        response = synth.get_canary(Name=canary_name)\n",
    "        status = response['Canary']['Status']['State']    \n",
    "        print('Canary status: {}'.format(status))\n",
    "        if status == 'ERROR':\n",
    "            raise(Exception(response['Canary']['Status']['StateReason']))    \n",
    "        elif status == 'READY':\n",
    "            synth.start_canary(Name=canary_name)\n",
    "        elif status == 'RUNNING':\n",
    "            break        \n",
    "    except ClientError as e:\n",
    "        if e.response[\"Error\"][\"Code\"] == \"ResourceNotFoundException\":\n",
    "            print('No canary found.')\n",
    "            break\n",
    "        print(e.response[\"Error\"][\"Message\"])\n",
    "    time.sleep(10)\n",
    "\n",
    "# Output a html link to the cloudwatch console\n",
    "HTML('<a target=\"_blank\" href=\"https://{0}.console.aws.amazon.com/cloudwatch/home?region={0}#synthetics:canary/detail/{1}\">CloudWatch Canary</a>'.format(region, canary_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dashboard\n",
    "\n",
    "Finally let's create a AWS CloudWatch Dashboard to visualize the key performane metrics and alarms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a target=\"_blank\" href=\"https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#dashboards:name=mlops-bb-proj\">CloudWatch Dashboard</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sts = boto3.client('sts')\n",
    "account_id = sts.get_caller_identity().get('Account')\n",
    "dashboard_name = 'mlops-{}'.format(model_name)\n",
    "\n",
    "with open('dashboard.json') as f:\n",
    "    dashboard_body = Template(f.read()).substitute(region=region, account_id=account_id, model_name=model_name)\n",
    "    response = cloudwatch.put_dashboard(\n",
    "        DashboardName=dashboard_name,\n",
    "        DashboardBody=dashboard_body\n",
    "    )\n",
    "\n",
    "# Output a html link to the cloudwatch dashboard\n",
    "HTML('<a target=\"_blank\" href=\"https://{0}.console.aws.amazon.com/cloudwatch/home?region={0}#dashboards:name={1}\">CloudWatch Dashboard</a>'.format(region, canary_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigger Retraining\n",
    "\n",
    "Our CodePipeline is configured with a [CloudWatch Events](https://docs.aws.amazon.com/codepipeline/latest/userguide/create-cloudtrail-S3-source.html) to start our pipeline for retraining when the drift detection metric alrams.\n",
    "\n",
    "We can simulate drift by putting metric `0.5` which is above the threshold of `0.2`.  This will trigger the alarm, and start the code pipeline retraining.\n",
    "\n",
    "Click through to the Alarm and CodePipeline with the links below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a target=\"_blank\" href=\"https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#alarmsV2:alarm/mlops-nyctaxi-metric-gt-threshold\">CloudWatch Alarm</a> starts \n",
       "     <a target=\"_blank\" href=\"https://us-east-1.console.aws.amazon.com/codesuite/codepipeline/pipelines/bb-proj/view?region=us-east-1\">Code Pipeline</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Put a new metric to trigger an alaram\n",
    "response = cloudwatch.put_metric_data(\n",
    "    Namespace='aws/sagemaker/Endpoints/data-metrics',\n",
    "    MetricData=[\n",
    "        {\n",
    "            'MetricName': 'feature_baseline_drift_total_amount',\n",
    "            'Dimensions': [\n",
    "                {\n",
    "                    'Name': 'MonitoringSchedule',\n",
    "                    'Value': schedule_name\n",
    "                },\n",
    "                {\n",
    "                    'Name': 'Endpoint',\n",
    "                    'Value': prd_endpoint_name\n",
    "                },\n",
    "            ],\n",
    "            'Timestamp': datetime.now(),\n",
    "            'Value': 0.5, # This is over the configured threshold of 0.2\n",
    "            'Unit': 'None'\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Output a html link to the cloudwatch dashboard\n",
    "alarm_name = 'mlops-nyctaxi-metric-gt-threshold'\n",
    "HTML('''<a target=\"_blank\" href=\"https://{0}.console.aws.amazon.com/cloudwatch/home?region={0}#alarmsV2:alarm/{1}\">CloudWatch Alarm</a> starts \n",
    "     <a target=\"_blank\" href=\"https://{0}.console.aws.amazon.com/codesuite/codepipeline/pipelines/{2}/view?region={0}\">Code Pipeline</a>'''.format(region, alarm_name, pipeline_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train = sagemaker.inputs.TrainingInput(\"s3://{}/{}/{}/\".format(bucket, pl_prefix, 'data/training'), content_type='text/csv')\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(\"s3://{}/{}/{}/\".format(bucket, pl_prefix, 'data/validation'), content_type='text/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_container = sagemaker.image_uris.retrieve('xgboost', boto3.Session().region_name, '1.0-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_type='ml.m5.xlarge'\n",
    "\n",
    "hyperparameters = {\n",
    "        \"alpha\":\"0.2\",\n",
    "        \"max_depth\":\"10\",\n",
    "        \"eta\":\"0.12\",\n",
    "        \"gamma\":\"2.0\",\n",
    "        \"min_child_weight\":\"8.5\",\n",
    "        \"subsample\":\"0.6\",\n",
    "        \"objective\":\"binary:logistic\",\n",
    "        \"num_round\":\"20\",\n",
    "        \"eval_metric\":\"auc\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_xgb = sagemaker.estimator.Estimator(image_uri=xgboost_container,\n",
    "                                          hyperparameters=hyperparameters,\n",
    "                                          role=sagemaker.get_execution_role(), \n",
    "                                          instance_count=1, \n",
    "                                          instance_type=instance_type,\n",
    "                                          output_path=s3_output_location,\n",
    "                                          sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "smote_xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})\n",
    "\n",
    "# use if you only want to train and not validate\n",
    "# smote_xgb.fit({'train': s3_input_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "deploy_instance_type='ml.m5.large'\n",
    "smote_predictor = smote_xgb.deploy(initial_instance_count=1,\n",
    "                                   model_name=\"xgb-smote-model-02\",\n",
    "                                   endpoint_name=\"xgb-smote-endpoint-02\",\n",
    "                                   instance_type=deploy_instance_type,\n",
    "                                   serializer=CSVSerializer(),\n",
    "                                   deserializer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use if already deployed\n",
    "\n",
    "# endpoint_name = \"xgb-smote-endpoint-02\"\n",
    "# smote_predictor = sagemaker.predictor.Predictor(endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have trained the model we can use it to make predictions for the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(current_predictor, data, rows=500):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = ''\n",
    "    for array in split_array:\n",
    "        predictions = ','.join([predictions, current_predictor.predict(array).decode('utf-8')])\n",
    "\n",
    "    return np.fromstring(predictions[1:], sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "smote_raw_predictions = predict(smote_predictor, X_test[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_binary_predictions = np.where(smote_raw_predictions > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_train_preds = predict(smote_predictor, X_train[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_valid_preds = predict(smote_predictor, X_val[:, 1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_specificity(y_actual, y_pred, thresh):\n",
    "    # calculates specificity\n",
    "    return sum((y_pred < thresh) & (y_actual == 0)) /sum(y_actual ==0)\n",
    "\n",
    "def print_report(y_actual, y_pred, thresh):\n",
    "    \n",
    "    auc = roc_auc_score(y_actual, y_pred)\n",
    "    accuracy = accuracy_score(y_actual, (y_pred > thresh))\n",
    "    recall = recall_score(y_actual, (y_pred > thresh))\n",
    "    precision = precision_score(y_actual, (y_pred > thresh))\n",
    "    specificity = calc_specificity(y_actual, y_pred, thresh)\n",
    "\n",
    "    print('AUC:%.3f'%auc)\n",
    "    print('accuracy:%.3f'%accuracy)\n",
    "    print('recall:%.3f'%recall)\n",
    "    print('precision:%.3f'%precision)\n",
    "    print('specificity:%.3f'%specificity)\n",
    "    print(' ')\n",
    "    return auc, accuracy, recall, precision, specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's have a look at our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "AUC:0.767\n",
      "accuracy:0.683\n",
      "recall:0.332\n",
      "precision:0.939\n",
      "specificity:0.982\n",
      " \n",
      "Validation:\n",
      "AUC:0.752\n",
      "accuracy:0.688\n",
      "recall:0.388\n",
      "precision:0.884\n",
      "specificity:0.955\n",
      " \n"
     ]
    }
   ],
   "source": [
    "thresh = 0.1\n",
    "\n",
    "# print('XGBoost Classifier')\n",
    "print('Training:')\n",
    "xgb_train_auc, xgb_train_accuracy, xgb_train_recall, xgb_train_precision, xgb_train_specificity = print_report(y_train, y_train_preds, thresh)\n",
    "\n",
    "print('Validation:')\n",
    "xgb_valid_auc, xgb_valid_accuracy, xgb_valid_recall, xgb_valid_precision, xgb_valid_specificity = print_report(y_val, y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's have a look at the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_test, y_pred):\n",
    "\n",
    "    cm  = confusion_matrix(y_test, y_pred)\n",
    "    # Get the per-class normalized value for each cell\n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    # We color each cell according to its normalized value, annotate with exact counts.\n",
    "    ax = sns.heatmap(cm_norm, annot=cm, fmt=\"d\", cmap=\"Blues\")\n",
    "    ax.set(xticklabels=[\"non-fraud\", \"fraud\"], yticklabels=[\"non-fraud\", \"fraud\"])\n",
    "    ax.set_ylim([0,2])\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('Real Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_confusion_matrix(y_test, smote_binary_predictions)\n",
    "plot_confusion_matrix(y_test, smote_binary_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and now let's have a look at a ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "auc = round(roc_auc_score(y_train, y_train_preds), 4)\n",
    "print('AUC is ' + repr(auc))\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(y_train, y_train_preds)\n",
    "\n",
    "plt.title('ROC Curve')\n",
    "plt.plot(fpr, tpr, 'b',\n",
    "label='AUC = %0.2f'% auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.1])\n",
    "plt.ylim([-0.1,1.1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and finally we need to clean up all our resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_predictor.delete_model()\n",
    "smote_predictor.delete_endpoint()\n",
    "sm_client = boto3.client('sagemaker', region_name=boto3.Session().region_name)\n",
    "waiter = sm_client.get_waiter('endpoint_deleted')\n",
    "waiter.wait(EndpointName=\"xgb-smote-endpoint-02\")"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
