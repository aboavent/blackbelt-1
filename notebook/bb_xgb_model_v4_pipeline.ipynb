{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Banking Fraud with various Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import AWS specific modules and specify S3 data location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install --upgrade pip\n",
    "# !{sys.executable} -m pip install --upgrade seaborn\n",
    "# !{sys.executable} -m pip install --upgrade imbalanced-learn\n",
    "import boto3\n",
    "import os\n",
    "from random import seed, sample\n",
    "import sagemaker\n",
    "import sagemaker.amazon.amazon_estimator\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.serializers import CSVSerializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import python ML modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score, roc_curve, auc, precision_score, recall_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'sagemaker-pmelvin'\n",
    "prefix = 'compile_xgb_v3'\n",
    "hp_prefix = 'hp_tuning_v3'\n",
    "\n",
    "csv_data = 'input-data/bb_banking_fraud.csv'\n",
    "csv_removed_types = 'input-data/removed-specific-types/01a89090-e9b6-4b07-8a49-b0244d6dc035.csv'\n",
    "full_data_location = 's3://{}/{}'.format(bucket, csv_data)\n",
    "clean_data_location = 's3://{}/{}'.format(bucket, csv_data)\n",
    "\n",
    "#local_file = 'bb_banking_fraud.csv'\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "smclient = boto3.Session().client('sagemaker')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_full = pd.read_csv(full_data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# df_clean = pd.read_csv(clean_data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_u = df_full.rename(columns={'oldbalanceOrg':'oldBalanceOrig', 'newbalanceOrig':'newBalanceOrig', 'oldbalanceDest':'oldBalanceDest', 'newbalanceDest':'newBalanceDest', 'isfraud':'isFraud'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_u.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_u_copy = df_u.copy()\n",
    "\n",
    "df_u['hourOfDay'] = np.nan\n",
    "df_u.hourOfDay = df_u_copy.step % 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_col = df_u.pop('isFraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_u.insert(0, 'isFraud', first_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_u.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df_u['isFraud'].value_counts()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts / df_u.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df_u.sample(n=10000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.isFraud.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(df):\n",
    "    \n",
    "    selected_cols = [\n",
    "        'type', 'amount', 'oldBalanceOrig', 'newBalanceOrig',\n",
    "        'oldBalanceDest', 'newBalanceDest', 'isFraud', 'hourOfDay'\n",
    "    ]\n",
    "    \n",
    "    df = df[selected_cols].copy()\n",
    "    dummies = pd.get_dummies(df.type)\n",
    "    df = pd.concat([df, dummies], axis=1).drop(\"type\", axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_data(pca_df):\n",
    "    pca_df = pca_df.copy()\n",
    "    target = pca_df.pop(\"isFraud\")\n",
    "    scaler = StandardScaler()\n",
    "    pca_df = scaler.fit_transform(pca_df)\n",
    "    pca = PCA(n_components=2)\n",
    "    components = pca.fit_transform(pca_df)\n",
    "\n",
    "    comp_df = pd.DataFrame(components, columns=[\"X\", \"y\"])\n",
    "    target = target.reset_index(drop=True)\n",
    "    plot_df = pd.concat([comp_df, target], axis=1)\n",
    "    \n",
    "    return plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fraud_plot(plot_df, maj_alpha=0.5, min_alpha=1, save=None):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax = sns.scatterplot(x=\"X\", y=\"y\", alpha=maj_alpha, data=plot_df[plot_df.isFraud == 0], label=\"Legitimate\")\n",
    "    sns.scatterplot(x=\"X\", y=\"y\", alpha=min_alpha, data=plot_df[plot_df.isFraud == 1], ax=ax, label=\"Fraud\")\n",
    "    plt.title(\"Legitimate vs Fraudulent Purchases\")\n",
    "    plt.tight_layout()\n",
    "    if save != None:\n",
    "        plt.savefig(save)\n",
    "    plt.show()\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = get_features(sample)\n",
    "plot_df = reduce_data(processed_data)\n",
    "fraud_plot(plot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_data.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUS = RandomUnderSampler(sampling_strategy={0: 9589}, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(df, method):\n",
    "    processed_df = get_features(df)\n",
    "    target = processed_df.pop('isFraud')\n",
    "\n",
    "    processed_x, processed_y = method.fit_resample(processed_df, target)\n",
    "\n",
    "    cols = list(processed_df.columns) + [\"isFraud\"]\n",
    "\n",
    "    pdf_x = pd.DataFrame(processed_x, columns=processed_df.columns)\n",
    "    pdf_y = pd.DataFrame(processed_y, columns=['isFraud'])\n",
    "    resampled_df = pd.concat([pdf_x, pdf_y], axis=1)\n",
    "    \n",
    "    return resampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rus_resampled = resample(df_u, RUS)\n",
    "print(rus_resampled.shape)\n",
    "print(rus_resampled.isFraud.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_plot(reduce_data(rus_resampled), min_alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SM = SMOTE(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sm_resampled = resample(df_u, SM)\n",
    "print(sm_resampled.shape)\n",
    "print(sm_resampled.isFraud.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_sample = sm_resampled.sample(n=10000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_plot(reduce_data(sm_sample), min_alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Splitting and standardising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to allow reproducible splitting we define a RandomState and seed\n",
    "# randomstate = 25\n",
    "# seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_col = rus_resampled.pop('isFraud')\n",
    "rus_resampled.insert(0, 'isFraud', first_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus_resampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "\n",
    "# columns = list(rus_resampled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "\n",
    "# train_df, val_df = train_test_split(rus_resampled, test_size=0.20, random_state=42)\n",
    "# val_df, test_df = train_test_split(val_df, test_size=0.05, random_state=42)\n",
    "\n",
    "# # Set the index for our test dataframe\n",
    "# test_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# print('split train: {}, val: {}, test: {} '.format(train_df.shape[0], val_df.shape[0], test_df.shape[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rus_resampled.drop('isFraud', 1)\n",
    "y = rus_resampled.isFraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.head(n=5)\n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y.head(n=5)\n",
    "# y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split the dataset with a 80% for training, 15% for validation and 5% for testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.80\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.05\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1 - train_ratio, random_state=42)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1 - train_ratio, random_state=42, shuffle=True, stratify=y)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), random_state=42) \n",
    "# X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), random_state=42, shuffle=True, stratify=y) \n",
    "\n",
    "print('split train: {}, val: {}, test: {} '.format(X_train.shape[0], X_val.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_val, X_test = np.split(rus_resampled.sample(frac=1), [int(0.7 * len(rus_resampled)), int(0.9 * len(rus_resampled))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "# scaler = RobustScaler()\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old way\n",
    "\n",
    "# X_train = scaler.transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "# X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train),columns = X_train.columns)\n",
    "X_test  = pd.DataFrame(scaler.fit_transform(X_test),columns = X_test.columns)\n",
    "X_val   = pd.DataFrame(scaler.fit_transform(X_val),columns = X_val.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "X_train_ins = X_train.copy()\n",
    "X_test_ins  = X_test.copy()\n",
    "X_val_ins   = X_val.copy()\n",
    "\n",
    "X_train_ins.insert(0, 'isFraud', y_train.values)\n",
    "X_test_ins.insert(0, 'isFraud', y_test.values)\n",
    "X_val_ins.insert(0, 'isFraud', y_val.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "X_train.to_csv('train.csv', index=False, header=False)\n",
    "X_val.to_csv('validation.csv', index=False, header=False)\n",
    "\n",
    "# Save test and baseline with headers\n",
    "X_test.to_csv('test.csv', index=False, header=True)\n",
    "X_train.to_csv('baseline.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# convert to numpy arrays for later use\n",
    "X_train = X_train.to_numpy()\n",
    "X_test  = X_test.to_numpy()\n",
    "X_val   = X_val.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save train and validation\n",
    "# X_train_ins.to_csv('train.csv', index=False, header=False)\n",
    "# X_val_ins.to_csv('validation.csv', index=False, header=False)\n",
    "\n",
    "# # Save test and baseline with headers\n",
    "# X_test_ins.to_csv('test.csv', index=False, header=True)\n",
    "# X_train_ins.to_csv('baseline.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# X_train_ins = X_train_ins.to_numpy()\n",
    "# X_test_ins  = X_test_ins.to_numpy()\n",
    "# X_val_ins   = X_val_ins.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old way\n",
    "\n",
    "# np.savetxt('train.csv', X_train, delimiter=',')\n",
    "# np.savetxt('test.csv', X_test, delimiter=',')\n",
    "# np.savetxt('validation.csv', X_val, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old way\n",
    "\n",
    "# boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "# s3_train_location = 's3://{}/{}/train'.format(bucket, prefix)\n",
    "# print('Uploaded training data location: {}'.format(s3_train_location))\n",
    "\n",
    "# boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'test/test.csv')).upload_file('test.csv')\n",
    "# s3_test_location = 's3://{}/{}/test'.format(bucket, prefix)\n",
    "# print('Uploaded test data location: {}'.format(s3_test_location))\n",
    "\n",
    "# boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'validation/validation.csv')).upload_file('validation.csv')\n",
    "# s3_validation_location = 's3://{}/{}/validation'.format(bucket, prefix)\n",
    "# print('Uploaded validation data location: {}'.format(s3_validation_location))\n",
    "\n",
    "# s3_output_location = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "# print('Training artifacts will be uploaded to: {}'.format(s3_output_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old way\n",
    "# s3_input_train = sagemaker.inputs.TrainingInput(\"s3://{}/{}/{}/\".format(bucket, prefix, 'train'), content_type='text/csv')\n",
    "# s3_input_validation = sagemaker.inputs.TrainingInput(\"s3://{}/{}/{}/\".format(bucket, prefix, 'validation'), content_type='text/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_prefix = 'pipeline'\n",
    "\n",
    "s3_train_uri = sess.upload_data('train.csv', bucket, pl_prefix + '/data/training')\n",
    "print('Uploaded training data location: {}'.format(s3_train_uri))\n",
    "\n",
    "s3_val_uri = sess.upload_data('validation.csv', bucket, pl_prefix + '/data/validation')\n",
    "print('Uploaded validation data location: {}'.format(s3_val_uri))\n",
    "\n",
    "s3_baseline_uri = sess.upload_data('baseline.csv', bucket, pl_prefix + '/data/baseline')\n",
    "print('Uploaded validation data location: {}'.format(s3_baseline_uri))\n",
    "\n",
    "s3_output_location = 's3://{}/{}/output'.format(bucket, pl_prefix)\n",
    "print('Training artifacts will be uploaded to: {}'.format(s3_output_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train = sagemaker.inputs.TrainingInput(\"s3://{}/{}/{}/\".format(bucket, pl_prefix, 'data/training'), content_type='text/csv')\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(\"s3://{}/{}/{}/\".format(bucket, pl_prefix, 'data/validation'), content_type='text/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_container = sagemaker.image_uris.retrieve('xgboost', boto3.Session().region_name, '1.0-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_type='ml.m5.xlarge'\n",
    "\n",
    "hyperparameters = {\n",
    "        \"alpha\":\"0.2\",\n",
    "        \"max_depth\":\"10\",\n",
    "        \"eta\":\"0.12\",\n",
    "        \"gamma\":\"2.0\",\n",
    "        \"min_child_weight\":\"8.5\",\n",
    "        \"subsample\":\"0.6\",\n",
    "        \"objective\":\"binary:logistic\",\n",
    "        \"num_round\":\"20\",\n",
    "        \"eval_metric\":\"auc\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_xgb = sagemaker.estimator.Estimator(image_uri=xgboost_container,\n",
    "                                          hyperparameters=hyperparameters,\n",
    "                                          role=sagemaker.get_execution_role(), \n",
    "                                          instance_count=1, \n",
    "                                          instance_type=instance_type,\n",
    "                                          output_path=s3_output_location,\n",
    "                                          sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "smote_xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})\n",
    "\n",
    "# use if you only want to train and not validate\n",
    "# smote_xgb.fit({'train': s3_input_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "smote_predictor = smote_xgb.deploy(initial_instance_count=1,\n",
    "                                   model_name=\"xgb-smote-model-02\",\n",
    "                                   endpoint_name=\"xgb-smote-endpoint-02\",\n",
    "                                   instance_type=\"ml.t3.medium\",\n",
    "                                   serializer=CSVSerializer(),\n",
    "                                   deserializer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use if already deployed\n",
    "\n",
    "# endpoint_name = \"xgb-smote-endpoint-01\"\n",
    "# smote_predictor = sagemaker.predictor.Predictor(endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have trained the model we can use it to make predictions for the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(current_predictor, data, rows=500):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = ''\n",
    "    for array in split_array:\n",
    "        predictions = ','.join([predictions, current_predictor.predict(array).decode('utf-8')])\n",
    "\n",
    "    return np.fromstring(predictions[1:], sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "smote_raw_predictions = predict(smote_predictor, X_test[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_binary_predictions = np.where(smote_raw_predictions > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_train_preds = predict(smote_predictor, X_train[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_valid_preds = predict(smote_predictor, X_val[:, 1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all of the various pieces we need to visualise these numbers, we will be using:\n",
    "\n",
    "- auc\n",
    "- accuracy\n",
    "- recall\n",
    "- precision\n",
    "- specificity\n",
    "\n",
    "and then a confusion matrix and a ROC curve!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**auc**\n",
    "\n",
    "AUC means area under the curve so to speak about ROC AUC score we need to define ROC curve first. \n",
    "\n",
    "It is a chart that visualizes the tradeoff between true positive rate (TPR) and false positive rate (FPR). Basically, for every threshold, we calculate TPR and FPR and plot it on one chart.\n",
    "\n",
    "**accuracy**\n",
    "\n",
    "It measures how many observations, both positive and negative, were correctly classified.\n",
    "\n",
    "**recall**\n",
    "\n",
    "Recall is the ratio of the correctly +ve labeled, i.e. which transactions are actually fraudulent\n",
    "\n",
    "**precision**\n",
    "\n",
    "Precision is the ratio of the correctly +ve labeled by our program to all +ve labeled.\n",
    "\n",
    "**specificity**\n",
    "\n",
    "Specificity is the *correctly* -ve labeled by the program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have define some functions to output all the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_specificity(y_actual, y_pred, thresh):\n",
    "    # calculates specificity\n",
    "    return sum((y_pred < thresh) & (y_actual == 0)) /sum(y_actual ==0)\n",
    "\n",
    "def print_report(y_actual, y_pred, thresh):\n",
    "    \n",
    "    auc = roc_auc_score(y_actual, y_pred)\n",
    "    accuracy = accuracy_score(y_actual, (y_pred > thresh))\n",
    "    recall = recall_score(y_actual, (y_pred > thresh))\n",
    "    precision = precision_score(y_actual, (y_pred > thresh))\n",
    "    specificity = calc_specificity(y_actual, y_pred, thresh)\n",
    "\n",
    "    print('AUC:%.3f'%auc)\n",
    "    print('accuracy:%.3f'%accuracy)\n",
    "    print('recall:%.3f'%recall)\n",
    "    print('precision:%.3f'%precision)\n",
    "    print('specificity:%.3f'%specificity)\n",
    "    print(' ')\n",
    "    return auc, accuracy, recall, precision, specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's have a look at our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.1\n",
    "\n",
    "print('XGBoost Classifier')\n",
    "print('Training:')\n",
    "xgb_train_auc, xgb_train_accuracy, xgb_train_recall, xgb_train_precision, xgb_train_specificity = print_report(y_train, y_train_preds, thresh)\n",
    "\n",
    "print('Validation:')\n",
    "xgb_valid_auc, xgb_valid_accuracy, xgb_valid_recall, xgb_valid_precision, xgb_valid_specificity = print_report(y_val, y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's have a look at the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_test, y_pred):\n",
    "\n",
    "    cm  = confusion_matrix(y_test, y_pred)\n",
    "    # Get the per-class normalized value for each cell\n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    # We color each cell according to its normalized value, annotate with exact counts.\n",
    "    ax = sns.heatmap(cm_norm, annot=cm, fmt=\"d\", cmap=\"Blues\")\n",
    "    ax.set(xticklabels=[\"non-fraud\", \"fraud\"], yticklabels=[\"non-fraud\", \"fraud\"])\n",
    "    ax.set_ylim([0,2])\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('Real Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_confusion_matrix(y_test, smote_binary_predictions)\n",
    "plot_confusion_matrix(y_test, smote_binary_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and now let's have a look at a ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "auc = round(roc_auc_score(y_train, y_train_preds), 4)\n",
    "print('AUC is ' + repr(auc))\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(y_train, y_train_preds)\n",
    "\n",
    "plt.title('ROC Curve')\n",
    "plt.plot(fpr, tpr, 'b',\n",
    "label='AUC = %0.2f'% auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.1])\n",
    "plt.ylim([-0.1,1.1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question is how to improve on the above as although it is ok it is far from from perfect\n",
    "\n",
    "What we need to do is change the hyperparamters but there are a lot of hyperparamters and an almost infinite numbe of possibilities\n",
    "\n",
    "We need some sort of automation, is there anything?\n",
    "\n",
    "**Hyperperamater Tuning** to the rescue!\n",
    "\n",
    "from the offical documentation\n",
    "\n",
    "*Amazon SageMaker automatic model tuning, also known as hyperparameter tuning, finds the best version of a model by running many training jobs on your dataset using the algorithm and ranges of hyperparameters that you specify. It then chooses the hyperparameter values that result in a model that performs the best, as measured by a metric that you choose.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to define some more information for the tuner, which most importantly includes the hyperparameter ranges to test between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "tuning_job_name = 'xgboost-tuning-job-' + strftime(\"%d-%H-%M-%S\", gmtime())\n",
    "s3_tuning_output = 's3://{}/{}/{}'.format(bucket, hp_prefix, tuning_job_name)\n",
    "\n",
    "tuning_job_config = {\n",
    "    \"ParameterRanges\": {\n",
    "      \"CategoricalParameterRanges\": [],\n",
    "      \"ContinuousParameterRanges\": [\n",
    "        {\n",
    "          \"MaxValue\": \"8\",\n",
    "          \"MinValue\": \"0\",\n",
    "          \"Name\": \"alpha\"\n",
    "        },\n",
    "        {\n",
    "          \"MaxValue\": \"0.8\",\n",
    "          \"MinValue\": \"0.1\",\n",
    "          \"Name\": \"eta\"\n",
    "        },\n",
    "        {\n",
    "          \"MaxValue\": \"5\",\n",
    "          \"MinValue\": \"0\",\n",
    "          \"Name\": \"gamma\"\n",
    "        },\n",
    "        {\n",
    "          \"MaxValue\": \"10\",\n",
    "          \"MinValue\": \"1\",\n",
    "          \"Name\": \"min_child_weight\"\n",
    "        }\n",
    "      ],\n",
    "      \"IntegerParameterRanges\": [\n",
    "        {\n",
    "          \"MaxValue\": \"20\",\n",
    "          \"MinValue\": \"1\",\n",
    "          \"Name\": \"max_depth\"\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    \"ResourceLimits\": {\n",
    "      \"MaxNumberOfTrainingJobs\": 20,\n",
    "      \"MaxParallelTrainingJobs\": 3\n",
    "    },\n",
    "    \"Strategy\": \"Bayesian\",\n",
    "    \"HyperParameterTuningJobObjective\": {\n",
    "      \"MetricName\": \"validation:auc\",\n",
    "      \"Type\": \"Maximize\"\n",
    "    }\n",
    "  }\n",
    "\n",
    "training_job_definition = {\n",
    "    \"AlgorithmSpecification\": {\n",
    "      \"TrainingImage\": xgboost_container,\n",
    "      \"TrainingInputMode\": \"File\"\n",
    "    },\n",
    "    \"InputDataConfig\": [\n",
    "      {\n",
    "        \"ChannelName\": \"train\",\n",
    "        \"CompressionType\": \"None\",\n",
    "        \"ContentType\": \"csv\",\n",
    "        \"DataSource\": {\n",
    "          \"S3DataSource\": {\n",
    "            \"S3DataDistributionType\": \"FullyReplicated\",\n",
    "            \"S3DataType\": \"S3Prefix\",\n",
    "            \"S3Uri\": s3_train_uri\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"ChannelName\": \"validation\",\n",
    "        \"CompressionType\": \"None\",\n",
    "        \"ContentType\": \"csv\",\n",
    "        \"DataSource\": {\n",
    "          \"S3DataSource\": {\n",
    "            \"S3DataDistributionType\": \"FullyReplicated\",\n",
    "            \"S3DataType\": \"S3Prefix\",\n",
    "            \"S3Uri\": s3_val_uri\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    ],\n",
    "    \"OutputDataConfig\": {\n",
    "      \"S3OutputPath\": s3_tuning_output\n",
    "    },\n",
    "    \"ResourceConfig\": {\n",
    "      \"InstanceCount\": 1,\n",
    "      \"InstanceType\": instance_type,\n",
    "      \"VolumeSizeInGB\": 10\n",
    "    },\n",
    "    \"RoleArn\": role,\n",
    "    \"StaticHyperParameters\": {\n",
    "      \"eval_metric\": \"auc\",\n",
    "      \"num_round\": \"100\",\n",
    "      \"objective\": \"binary:logistic\",\n",
    "      \"rate_drop\": \"0.3\",\n",
    "      \"tweedie_variance_power\": \"1.4\"\n",
    "    },\n",
    "    \"StoppingCondition\": {\n",
    "      \"MaxRuntimeInSeconds\": 300\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smclient.create_hyper_parameter_tuning_job(HyperParameterTuningJobName = tuning_job_name,\n",
    "                                           HyperParameterTuningJobConfig = tuning_job_config,\n",
    "                                           TrainingJobDefinition = training_job_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smclient.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName=tuning_job_name)['HyperParameterTuningJobStatus']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we go to the console to have a look (and we can also wait until finished but I will just take a quick snapshot) we can see the training jobs running/completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "![title](img/training_jobs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and also the best training job that we can either manually use or look to integrate into a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "![title](img/best_training_job.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we now will get Sagemaker to do some autmatic tuning for us and we can check those results with any of the above methods!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use another method which will allow us to define another estimator and then use it to update models and endpoints\n",
    "\n",
    "This will be used in the next section when we talk about a pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So (again), first let's define a new estimator to change some of the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# tuning_xgb = sagemaker.estimator.Estimator(image_uri=xgboost_container,\n",
    "#                                           hyperparameters=hyperparameters,\n",
    "#                                           role=sagemaker.get_execution_role(), \n",
    "#                                           instance_count=1, \n",
    "#                                           instance_type=instance_type,\n",
    "#                                           output_path=s3_output_location,\n",
    "#                                           sagemaker_session=sess,\n",
    "#                                           max_run=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# from time import gmtime, strftime, sleep\n",
    "# from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "# tuning_job_name = 'xgboost-tuningjob-' + strftime(\"%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "# hyperparameter_ranges = {\n",
    "#                         'eta': ContinuousParameter(0.1, 0.5),\n",
    "#                         'min_child_weight': ContinuousParameter(1, 10),\n",
    "#                         'alpha': ContinuousParameter(0, 8),\n",
    "#                         'max_depth': IntegerParameter(0, 20),\n",
    "#                         'gamma': ContinuousParameter(0, 5)\n",
    "#                         }\n",
    "\n",
    "# objective_metric_name = 'validation:auc'\n",
    "\n",
    "# tuner = HyperparameterTuner(tuning_xgb,\n",
    "#                             objective_metric_name,\n",
    "#                             hyperparameter_ranges,\n",
    "#                             max_jobs=20,\n",
    "#                             max_parallel_jobs=3,\n",
    "#                             strategy='Random')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# tuner.fit({'train': s3_input_train, 'validation': s3_input_validation}, include_cls_metadata=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# smclient.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName=tuner.latest_tuning_job.job_name)['HyperParameterTuningJobStatus']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# tuner_predictor = tuner.deploy(initial_instance_count=1,\n",
    "#                                    model_name=\"xgb-tuner-model-01\",\n",
    "#                                    endpoint_name=\"xgb-tuner-endpoint-01\",\n",
    "#                                    instance_type=instance_type,\n",
    "#                                    serializer=CSVSerializer(),\n",
    "#                                    deserializer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and finally we need to clean up all our resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_predictor.delete_model()\n",
    "smote_predictor.delete_endpoint()\n",
    "sm_client = boto3.client('sagemaker', region_name=boto3.Session().region_name)\n",
    "waiter = sm_client.get_waiter('endpoint_deleted')\n",
    "waiter.wait(EndpointName=\"xgb-smote-endpoint-02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
